{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import csv\n",
    "from data_cleaning import (\n",
    "    string_pattern_search,\n",
    "    string_pattern_replace,\n",
    "    single_threaded_read_and_decode_lines,\n",
    "    load_data_into_dataframe,\n",
    "    detect_encoding_for_row\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Decode CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_raw = pd.read_csv(r\"D:\\ML\\Portfolio\\Projects\\semantic-search\\datasets\\metadata-matches-raw.txt\", encoding_errors='ignore') # File version converted to UTF-8 outside of Python for comparison\n",
    "\n",
    "file_path = r\"D:\\ML\\Portfolio\\Projects\\semantic-search\\datasets\\metadata-matches-original-encoding.txt\" # Original encoding version of the file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Use dynamic (line-by-line) decoding:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the single-threaded approach to read and decode the file line by line\n",
    "decoded_text, encodings_tried = single_threaded_read_and_decode_lines(file_path)\n",
    "\n",
    "# Print the encodings tried\n",
    "for encoding, confidence in encodings_tried:\n",
    "    print(f\"Tried encoding: {encoding} with confidence: {confidence}\")\n",
    "\n",
    "# Load the decoded text into a DataFrame\n",
    "meta_decoded = load_data_into_dataframe(decoded_text)\n",
    "\n",
    "# Display the DataFrame and check the number of rows\n",
    "print(meta_decoded.head())\n",
    "print(f\"Number of rows: {len(meta_decoded)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Encoding detector. Currently not utilised (not required):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example usage\n",
    "# Assuming df is your DataFrame\n",
    "# Specify the row index you want to check\n",
    "row_index = 779  # Change this to the row index you want to inspect\n",
    "\n",
    "# Detect encoding for the specified row\n",
    "encoding, confidence = detect_encoding_for_row(meta_decoded, row_index)\n",
    "print(f\"Row {row_index + 1}: Encoding={encoding}, Confidence={confidence:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Validate Decoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Edge cases:\n",
    "# 'C1014982': \n",
    "# 'C709663': † River †\n",
    "mask = meta_decoded['CAN_ID'] == 'C709663' # Spanish example: two separate encodings within the same line (word)\n",
    "meta_decoded[mask]\n",
    "\n",
    "meta_decoded.compare(meta_raw) # Compare the dynamically decoded vs. converted to UTF-8 dataframes "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Export CSV (if required)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#csv_export_path = \"D:\\ML\\Portfolio\\Projects\\RAG\\metadata-matches-decoded.txt\"\n",
    "\n",
    "#meta_decoded.to_csv(csv_export_path, index=False, quoting=csv.QUOTE_NONNUMERIC) # Quotes to prevent Pandas converting to numeric on import to preserve the original file data types."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Data Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_decoded.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_decoded.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.float_format', lambda x: f'{x:.2f}') # Prevent using scientific notation for SEQ_NO column when using .describe() method (due to wide value range in the column)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_decoded.describe(include='all')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Data Integrity Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pandas display setting management section:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pd.set_option('display.max_rows', None)\n",
    "#pd.reset_option('display.max_rows')\n",
    "#pd.set_option('display.max_colwidth', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Validate Values and Fix\n",
    "\n",
    "Review and normalise values.\n",
    "\n",
    "_**Songcode & ISWC**_ columns are out of the PoC/ prototype scope and won't be validated/ cleaned/ manipulated. They require additional consideration before validating values. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_default_all = meta_decoded.columns[2:] # Default column set (strings only).\n",
    "cols_default_strict = meta_decoded.columns[2:-2] # Default column set (strings only). Exclude Soncode & ISWCs columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Internal whitespaces followed by a number (canonical writer columns only):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "internal_whitespace_num_pat = (r'\\s{2,}\\d', True) # Match two or more whitespace characters, followed by a single digit\n",
    "internal_whitespace_num_cols = ['CAN_Writers_Formatted', 'CAN_Writers_Raw']\n",
    "\n",
    "internal_whitespace_num_df = string_pattern_search(meta_decoded, internal_whitespace_num_pat, internal_whitespace_num_cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Replace the pattern with an empty string and validate removal:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "string_pattern_replace(meta_decoded, internal_whitespace_num_pat, replace_with='', cols=internal_whitespace_num_cols) # Replace with an empty string and validate removal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.' [Not Controlled]' as part of some composition titles (this data is unrelated to the dataset):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "not_controled_pat = (' [Not Controlled]', False)\n",
    "\n",
    "not_controled_df = string_pattern_search(meta_decoded, not_controled_pat, cols_default_all)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Replace the pattern with an empty string and validate removal:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "string_pattern_replace(meta_decoded, not_controled_pat, replace_with='', cols=not_controled_df.columns) # Replace with an empty string and validate removal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. All extra whitespaces: leading, internal, trailing, non-breaking space (\\xa0), newline characters (\\n), etc.:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "string_pattern_replace(meta_decoded, (r'\\s+', True), replace_with=' ', cols=cols_default_strict) # Match one or more whitespace characters. Replace any whitespaces with a single space. Exclude songcodes & ISWCs\n",
    "\n",
    "for col in cols_default_strict: # Exclude songcodes & ISWCs\n",
    "    meta_decoded[col] = meta_decoded[col].str.strip() # Remove leading/ trailing whitespace (incl. non-breaking space)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Validate whitespace removal (songcodes and ISWCs are left untouched as intended):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "string_pattern_search(meta_decoded, (r'^\\s|\\s$|\\s{2,}', True), cols=cols_default_all, summary='unique') # Matches leading, trailing or consecutive whitespace characters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Curly apostrophe (right single quotation mark): '’'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "single_quote_pat = ('’', False)\n",
    "single_quote_pat_df = string_pattern_search(meta_decoded, single_quote_pat, cols=cols_default_all)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Replace the pattern with an empty string and validate removal:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "string_pattern_replace(meta_decoded, single_quote_pat, replace_with=\"'\", cols=single_quote_pat_df.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. CSV Export"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Data Type Check\n",
    "If any columns but the first two contain any numeric values (should be strings as are encapsulated in \"\" in the CSV)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if any columns contain numeric values\n",
    "for col in meta_decoded.columns[2:]:\n",
    "    # Drop NaN values before checking for numeric values\n",
    "    non_na_values = meta_decoded[col].dropna()\n",
    "    numeric_values = non_na_values.apply(lambda x: isinstance(x, (int, float)) and not isinstance(x, bool))\n",
    "    if numeric_values.any():\n",
    "        first_numeric_value = non_na_values[numeric_values].iloc[0]\n",
    "        print(f\"Column {col} contains numeric values. Example: {first_numeric_value}\")\n",
    "    else:\n",
    "        print(f\"Column {col} does not contain numeric values.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Export to CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_export_path = r\"D:\\ML\\Portfolio\\Projects\\semantic-search\\datasets\\metadata-matches-pre-processed.txt\"\n",
    "\n",
    "meta_decoded.to_csv(csv_export_path, index=False, quoting=csv.QUOTE_NONNUMERIC) # Quotes to prevent Pandas converting to numeric on import to preserve the original file data types. The empty strings are converted to NaN values on import."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. CSV Export Validation\n",
    "To check if any data loss on export."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_exported = pd.read_csv(csv_export_path)\n",
    "\n",
    "if meta_decoded.equals(meta_exported):\n",
    "    print('No data loss on CSV export!')\n",
    "else:\n",
    "    print('WARNING: Some data loss on CSV export!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The difference in the exported dataset is due to whitespaces only present in 'MATCHED_Writer_2', which got replaced with an empty string, which in turn got replaced with 'NaN' by pd.read_csv:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_exported.compare(meta_decoded)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Whitespace conversion to an empty string and then to 'NaN' for a sample value:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_raw.loc[31794, 'MATCHED_Writer_2'], meta_decoded.loc[31794, 'MATCHED_Writer_2'], meta_exported.loc[31794, 'MATCHED_Writer_2'] # unprocessed df, extra whitespace removed df, re-imported df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
